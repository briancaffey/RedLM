apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-deployment
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm
  template:
    metadata:
      labels:
        app: vllm
    spec:
      containers:
      - name: vllm-container
        image: vllm/vllm-openai
        args: ["--model", "01-ai/Yi-1.5-9B-Chat", "--max-model-len", "18160"]
        ports:
        - containerPort: 8000
        volumeMounts:
        - name: huggingface-cache
          mountPath: /root/.cache/huggingface
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-secret-llm
              key: HUGGING_FACE_HUB_TOKEN
      restartPolicy: Always
      volumes:
      - name: huggingface-cache
        persistentVolumeClaim:
          claimName: huggingface-pvc-llm
